{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "affecting-cloud",
   "metadata": {},
   "source": [
    "# Azure Mini Project: Data Factory\n",
    "![Design Blocks](https://images.unsplash.com/photo-1507823690283-48b0929e727b?ixid=MnwxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8&ixlib=rb-1.2.1&auto=format&fit=crop&w=1950&q=800)\n",
    "Image by: Quinten de Graaf\n",
    "\n",
    "\n",
    "## Table of contents\n",
    "* [What is this?](#what-is-this)\n",
    "* [Goal:](#goal)\n",
    "\n",
    "\n",
    "## What is this?\n",
    "Wide World Importers (WWI) imports products then resells them both to retailers and directly to the public. In an increasingly crowded market, they are always looking for ways to differentiate themselves and provide additional value to their customers.They are looking to pilot a data warehouse to provide additional information useful to their internal sales and marketing agents. They want to enable their agents to perform as-is and as-was analysis in order to price the items accurately and predict the product demand throughout the year.\n",
    "\n",
    "To extend their physical presence WWI recently acquired Smart Food, a supermarket business who provides comprehensive nutritional information to customers so they can make healthy decisions. SmartFoods runs a loyalty program where customers accumulate points on their purchases. WWI CIO is hoping to use the loyalty program information and the food nutrients database of SmartFoods to provide customers with a HealthSmart portal. The portal will be showing aggregated information on customers' important food nutrients (carbs, saturated fats, etc.) to promote healthy shopping.\n",
    "\n",
    "In this hands-on mini-project, youâ€™ll build an end-to-end solution for data warehousing using data lake methodology.\n",
    "\n",
    "## Goal:\n",
    "The goal here is to experience creating and utilizing Spark clusters, provisioning them with Azure, and getting a working overview to Spark data analytics.\n",
    "\n",
    "__In this mini-project, I will demonstrate competency in:__\n",
    "* Deploying an HDInsight Spark cluster\n",
    "* Working with content stored in Azure Blob Storage and accessed by the Spark cluster as an HDFS volume\n",
    "* Using a Jupyter Notebook to interactively explore a large dataset\n",
    "* Deleting a Spark cluster to avoid incurring unnecessary charges\n",
    "\n",
    "__Exercises:__\n",
    "* Exercise 1: Create a Spark Cluster on HDInsight\n",
    "* Exercise 2: Upload Jupyter Notebook to the cluster\n",
    "* Exercise 3: Work with Jupyter Notebooks\n",
    "* Exercise 4: Remove the HDInsight Spark cluster\n",
    "\n",
    "__Deliverables:__\n",
    "* 1. Jupyter Notebook with code to achieve stated objective in each cell\n",
    "* 2. A PPT/Word-doc with screenshots of each step as performed according to this lab\n",
    "_____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "painted-stretch",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
