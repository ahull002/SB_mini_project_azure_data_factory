{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "structured-darkness",
   "metadata": {},
   "source": [
    "# Azure Mini Project: Data Factory\n",
    "![Design Blocks](https://images.unsplash.com/photo-1507823690283-48b0929e727b?ixid=MnwxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8&ixlib=rb-1.2.1&auto=format&fit=crop&w=1950&q=800)\n",
    "Image by: Quinten de Graaf\n",
    "\n",
    "\n",
    "## Table of contents\n",
    "* [What is this?](#what-is-this)\n",
    "* [Business problem:](business-problem)\n",
    "* [Goal:](#goal)\n",
    "\n",
    "\n",
    "## What is this?\n",
    "In this mini-project, I have engineered and deployed an End-to-End Azure Extract Load Transformation (ELT) solution. I have done this using Azure Data Factory (ADF) and Mapping Dataflows to perform ELT process using Azure Blob storage and Azure SQL DB. I have also used Azure DevOps repositories to perform source control over ADF pipelines. Lastly, I have use Azure DevOps pipelines to deploy this project across multiple environments including Dev, Test, and Production.\n",
    "\n",
    "This hands-on mini-project is designed to provide exposure to many of Microsoft’s transformative lines of business applications. The goal is to show an end-to-end solution, leveraging many of these technologies, but not necessarily doing work in every component possible. \n",
    "\n",
    "> __The lab architecture is below and includes:__\n",
    "\n",
    "> * Azure Data Factory (ADF)\n",
    "> * Azure Storage\n",
    "> * Azure Data Factory Mapping Dataflows\n",
    "> * Azure SQL Database\n",
    "> * Azure Key vault\n",
    "> * Azure DevOps\n",
    "\n",
    "## Business problem:\n",
    "Wide World Importers (WWI) imports products then resells them both to retailers and directly to the public. In an increasingly crowded market, they are always looking for ways to differentiate themselves and provide additional value to their customers.They are looking to pilot a data warehouse to provide additional information useful to their internal sales and marketing agents. They want to enable their agents to perform as-is and as-was analysis in order to price the items accurately and predict the product demand throughout the year.\n",
    "\n",
    "To extend their physical presence WWI recently acquired Smart Food, a supermarket business who provides comprehensive nutritional information to customers so they can make healthy decisions. SmartFoods runs a loyalty program where customers accumulate points on their purchases. WWI CIO is hoping to use the loyalty program information and the food nutrients database of SmartFoods to provide customers with a HealthSmart portal. The portal will be showing aggregated information on customers' important food nutrients (carbs, saturated fats, etc.) to promote healthy shopping.\n",
    "\n",
    "In this hands-on mini-project, I have built an end-to-end solution for data warehousing using modern data lake methodology.\n",
    "\n",
    "## Goal:\n",
    "The goal here is to demonstrate proficiency in creating and utilizing ELT pipelines utilizing MS AZURE technologies.\n",
    "\n",
    "__Deliverables:__\n",
    "> * (Optional) A document with screenshots of each step as performed according to this lab.\n",
    "\n",
    "> 1. Why should one use Azure Key Vault when working in the Azure environment? What are the pros and cons? What are the alternatives?\n",
    "> 2. How do you achieve loop functionality within a Azure Data Factory pipeline? Why would you need to use this functionality in a data pipeline?\n",
    "> 3. What are expressions in Azure Data Factory? How are they helpful when designing a data pipeline? Please explain with an example.\n",
    "> 4. What are the pros and cons of parametrizing a dataset’s activity in Azure Data Factory?\n",
    "> 5. What are the different supported file formats and compression codecs in Azure Data Factory? When will you use a Parquet file over an ORC file? Why would you choose an AVRO file format over a Parquet file format.\n",
    "_____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "agreed-george",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
